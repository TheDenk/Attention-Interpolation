{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "408cdf71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import imageio\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, CLIPImageProcessor\n",
    "from diffusers import (\n",
    "    DDIMScheduler, \n",
    "    AutoencoderKL, \n",
    "    ControlNetModel,\n",
    "    StableDiffusionPipeline,\n",
    ")\n",
    "from denku import show_images\n",
    "from controlnet_aux import HEDdetector\n",
    "\n",
    "from iattention import IAttentionSDCPipeline\n",
    "from iattention.attention_processors import register_stablediffuion_attention_control\n",
    "from iattention.utils import correct_colors_hist\n",
    "from unet.unet_2d_condition import UNet2DConditionModel\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bc29822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_attention_colntrol(pipe, config):\n",
    "    pipe.set_storage_params(config['pipe_config'])\n",
    "    register_stablediffuion_attention_control(\n",
    "        pipe.unet,\n",
    "        **config['unet_config']\n",
    "    )\n",
    "    register_stablediffuion_attention_control(\n",
    "        pipe.controlnet,\n",
    "        **config['controlnet_config']\n",
    "    )\n",
    "\n",
    "def register_coefs(pipe, coefs):\n",
    "    for up_block in pipe.unet.up_blocks: \n",
    "        up_block.coefs = coefs\n",
    "    \n",
    "def get_capture_info(cap):\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    return height, width, fps, frame_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e68e552e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_path = 'runwayml/stable-diffusion-v1-5'\n",
    "pretrained_controlnet = 'lllyasviel/control_v11p_sd15_softedge'\n",
    "\n",
    "interpolation_config = {\n",
    "    'pipe_config': {\n",
    "        'interpolation_scheduler': 'ema',\n",
    "        'ema': 0.45,\n",
    "        'eta': 0.75,\n",
    "        'start_step': 0,\n",
    "        'end_step': 25,\n",
    "        'const_steps': 0,\n",
    "        'total_steps': 25,\n",
    "    },\n",
    "    'unet_config': {\n",
    "        'interpolation_scheduler': 'ema',\n",
    "        'ema': 0.62,\n",
    "        'eta': 0.87,\n",
    "        'start_step': 0,\n",
    "        'end_step': 25,\n",
    "        'const_steps': 0,\n",
    "        'total_steps': 25,\n",
    "        'use_interpolation':{\n",
    "            'key': False,\n",
    "            'query': False,\n",
    "            'value': False,\n",
    "            'attention_probs': True,\n",
    "            'out_linear': True\n",
    "        },\n",
    "        'attention_res': 32,\n",
    "        'allow_names': ['down', 'mid', 'up'],\n",
    "    },\n",
    "    'controlnet_config': {\n",
    "        'interpolation_scheduler': 'ema',\n",
    "        'ema': 0.625,\n",
    "        'eta': 0.875,\n",
    "        'start_step': 0,\n",
    "        'end_step': 25,\n",
    "        'const_steps': 0,\n",
    "        'total_steps': 25,\n",
    "        'use_interpolation': {\n",
    "            'key': False,\n",
    "            'query': False,\n",
    "            'value': False,\n",
    "            'attention_probs': True,\n",
    "            'out_linear': True,\n",
    "        },\n",
    "        'attention_res': 32,\n",
    "        'allow_names': ['down', 'mid'],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c2626f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"tokenizer\", \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5c8090",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"text_encoder\", \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "848e5f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = CLIPImageProcessor.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"feature_extractor\", \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feb79aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = AutoencoderKL.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"vae\", \n",
    "    torch_dtype=torch.float16\n",
    ")            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275697db",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"unet\", \n",
    "    torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cedf9773",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDIMScheduler.from_pretrained(\n",
    "    pretrained_model_path, \n",
    "    subfolder=\"scheduler\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef97183a",
   "metadata": {},
   "outputs": [],
   "source": [
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    pretrained_controlnet, \n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "processor = HEDdetector.from_pretrained('lllyasviel/Annotators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c1c8b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'iattention.stablediffusion_controlnet_pipeline.IAttentionSDCPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    }
   ],
   "source": [
    "pipe = IAttentionSDCPipeline(\n",
    "    vae=vae,\n",
    "    text_encoder=text_encoder,\n",
    "    tokenizer=tokenizer,\n",
    "    unet=unet,\n",
    "    scheduler=scheduler,  \n",
    "    feature_extractor=feature_extractor,\n",
    "    controlnet=controlnet,\n",
    "    safety_checker=None,\n",
    ").to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6adb1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs = {\n",
    "    1280: {\n",
    "        'backbone_coef': 1.4,\n",
    "        'skip_coef': 0.9,\n",
    "    },\n",
    "    640: {\n",
    "        'backbone_coef': 1.2,\n",
    "        'skip_coef': 0.1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "16a0cb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSED FRAME: 1 | TOTAL FRAMES: 1\r"
     ]
    }
   ],
   "source": [
    "register_attention_colntrol(pipe, interpolation_config)\n",
    "register_coefs(pipe, coefs)\n",
    "\n",
    "gen_config = {\n",
    "    'prompt': 'Professional high-quality wide-angle digital art of an iron man in helmet. photorealistic, epic fantasy, dramatic lighting, cinematic, extremely high detail, cinematic lighting, trending on artstation, cgsociety, realistic rendering of Unreal Engine 5, 8k, 4k, HQ, wallpaper',\n",
    "    'negative_prompt': 'lowres, worst quality, low quality',\n",
    "    'seed': 17,\n",
    "    'img_h': 512,\n",
    "    'img_w': 512,\n",
    "    'num_inference_steps': 25,\n",
    "    'guess_mode': True,\n",
    "    'original_output_size': True,\n",
    "    'controlnet_processor': 'softedge',  # softedge, pose, norm, canny, depth\n",
    "    'hist_normalize': 'lab',  # rgb, hsv\n",
    "    'input_video_path': '../video/input/man.mp4',\n",
    "    'output_video_path': '../video/output/man_ironman.mp4',\n",
    "}\n",
    "\n",
    "cap = cv2.VideoCapture(gen_config['input_video_path'])\n",
    "height, width, fps, frame_count = get_capture_info(cap)\n",
    "\n",
    "images = []\n",
    "first_image = None\n",
    "process_frames_count = 1\n",
    "\n",
    "for frame_num in range(frame_count):\n",
    "    print(f'PROCESSED FRAME: {frame_num} | TOTAL FRAMES: {min(process_frames_count, frame_count)}', end='\\r')\n",
    "    ret, image = cap.read()\n",
    "    if not ret or image is None:\n",
    "        continue\n",
    "    \n",
    "    if frame_num >= process_frames_count:\n",
    "        break\n",
    "        \n",
    "    img_size = (gen_config['img_w'], gen_config['img_h'])\n",
    "    image = cv2.resize(image, img_size)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    condition_image = processor(Image.fromarray(image))\n",
    "\n",
    "    result_img = pipe(\n",
    "        image=condition_image,\n",
    "        prompt=gen_config['prompt'],\n",
    "        negative_prompt=gen_config['negative_prompt'],\n",
    "        num_inference_steps=gen_config['num_inference_steps'],\n",
    "        generator=torch.manual_seed(gen_config['seed']),\n",
    "        guess_mode=gen_config['guess_mode'],\n",
    "    ).images[0]\n",
    "    result = np.array(result_img)\n",
    "    \n",
    "    if first_image is None:\n",
    "        first_image = result.copy()\n",
    "    else:\n",
    "        result = correct_colors_hist(first_image, result, gen_config['hist_normalize'])\n",
    "            \n",
    "    images.append(result)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f32d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_images(images, n_rows=1, figsize=(15, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0fe807e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.mimwrite(gen_config['output_video_path'], images, fps=fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "173b7cd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c6705a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82cc3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a2456f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "477e0e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0a971e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = pipe(\n",
    "#     prompt='black cat, night, moon. high quality, extrimely high detail, cinematic, 8k, 4k',\n",
    "#     num_inference_steps=50,\n",
    "#     guidance_scale=7.5,\n",
    "#     return_dict=True,\n",
    "# ).images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e326f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49294463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566f870a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
