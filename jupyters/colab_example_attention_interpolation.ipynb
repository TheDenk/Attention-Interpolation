{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOOvBlxainU4x7dDdpawFt5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheDenk/Attention-Interpolation/blob/main/jupyters/colab_example_attention_interpolation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPML1JwNpw0",
        "outputId": "d319bbbe-cb3e-4ce3-8b7c-99de78010ea0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Attention-Interpolation' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/TheDenk/Attention-Interpolation.git\n",
        "!pip install -r ./Attention-Interpolation/requirements.txt > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "import sys\n",
        "sys.path.append('./Attention-Interpolation')\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from omegaconf import OmegaConf\n",
        "from diffusers import ControlNetModel, DDIMScheduler, StableDiffusionPipeline\n",
        "\n",
        "from iattention import UNION_PIPELINES\n",
        "from iattention.utils import correct_colors_hist, show_image, show_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzOr1GZ1Ntdp",
        "outputId": "b57dddb4-d99c-455d-ded2-e5fa1be1d391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/controlnet_aux/mediapipe_face/mediapipe_face_common.py:7: UserWarning: The module 'mediapipe' is not installed. The package will have limited functionality. Please install it using the command: pip install 'mediapipe'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_info(cap):\n",
        "    width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    return height, width, fps, frame_count"
      ],
      "metadata": {
        "id": "Bm-6uzm4NtiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = OmegaConf.load('./Attention-Interpolation/configs/default.yaml')\n",
        "config['pipe_config']['total_steps'] = config['common']['num_inference_steps']\n",
        "config['unet_config']['total_steps'] = config['common']['num_inference_steps']\n",
        "config['controlnet_config']['total_steps'] = config['common']['num_inference_steps']\n",
        "config['common']['unet_from'] = None #'./Attention-Interpolation/models/deliberate_v2.safetensors'"
      ],
      "metadata": {
        "id": "F-6ruXzGNtlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = UNION_PIPELINES[config['pipeline']](config)"
      ],
      "metadata": {
        "id": "a5S46Lq9Ou2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config['common']['input_video_path'] = './Attention-Interpolation/video/input/man.mp4'\n",
        "config['common']['output_video_path'] = './Attention-Interpolation/video/output/video-from-jupyter.mp4'\n",
        "\n",
        "cap = cv2.VideoCapture(config['common']['input_video_path'])\n",
        "orig_height, orig_width, fps, frame_count = get_video_info(cap)\n",
        "\n",
        "print(f'\\n\\n[ VIDEO INFO | WxH: {orig_width}x{orig_height} | FPS: {fps} | FRAME COUNT: {frame_count} ]\\n\\n')\n",
        "\n",
        "img_h, img_w = config['common']['img_h'], config['common']['img_w']\n",
        "out_h, out_w = img_h, img_w\n",
        "if config['common']['original_output_size']:\n",
        "    out_h, out_w = orig_height, orig_width\n",
        "\n",
        "writer = cv2.VideoWriter(\n",
        "    config['common']['output_video_path'],\n",
        "    cv2.VideoWriter_fourcc(*'mp4v'),\n",
        "    fps,\n",
        "    (out_w * 2, out_h),\n",
        ")\n",
        "\n",
        "first_image = None\n",
        "for _ in tqdm(range(frame_count)):\n",
        "    c_ret, c_image = cap.read()\n",
        "    if not c_ret or c_image is None:\n",
        "        break\n",
        "    image = cv2.resize(c_image, (img_h, img_w))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    result = pipe(image)\n",
        "\n",
        "    if first_image is None:\n",
        "        first_image = result.copy()\n",
        "    else:\n",
        "        predict_image = correct_colors_hist(first_image, result, config['common']['hist_normalize'])\n",
        "\n",
        "    out_images = [cv2.resize(x, (out_w, out_h)) for x in [image, result]]\n",
        "    result = np.hstack(out_images)\n",
        "    result = cv2.cvtColor(result, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    writer.write(result)\n",
        "\n",
        "\n",
        "cap.release()\n",
        "writer.release()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef3itpiJOu5d",
        "outputId": "ccd310bc-d3f0-4635-a44c-937673789de2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[ VIDEO INFO | WxH: 750x720 | FPS: 30 | FRAME COUNT: 36 ]\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36/36 [09:14<00:00, 15.41s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wXytYFCNOu70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Bn0g5tUOu9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DsTEypGgOu_8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}